import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, r2_score
from sklearn.linear_model import LogisticRegression
import scipy.stats as stats
from scipy.stats import pearsonr, spearmanr
import warnings
warnings.filterwarnings('ignore')

class PollutionIndicatorAnalyzer:
    """
    ìƒë¬¼ ë‹¤ì–‘ì„± ì§€í‘œ vs í™˜ê²½ ì§€í‘œì˜ ì˜¤ì—¼ë„ ì„¤ëª…ë ¥ ë¹„êµ ë¶„ì„ ì‹œìŠ¤í…œ
    Streamlitê³¼ Plotlyë¥¼ ì‚¬ìš©í•œ ëŒ€í™”í˜• ë¶„ì„ ë„êµ¬
    """
    
    def __init__(self):
        self.data = None
        self.bio_indicators = None
        self.env_indicators = None
        self.pollution_target = 'Pollution Level'
        self.results = {}
        
    def load_data(self, data):
        """ë°ì´í„° ë¡œë“œ ë° ì§€í‘œ ë¶„ë¥˜"""
        self.data = data
        
        # ìƒë¬¼ ë‹¤ì–‘ì„± ì§€í‘œ ì •ì˜
        self.bio_indicators = [
            'Mean Number of Nematode species 1 per gram soil',
            'Mean Number of Turbillaria per gram soil',
            'Mean Number of foraminefera per gram soil',
            'Mean Number of Nematode species 2 per gram soil',
            'Organic matter%'
        ]
        
        # í™˜ê²½ ì§€í‘œ ì •ì˜ (í™”í•™ì  + ë¬¼ë¦¬ì )
        self.env_indicators = [
            'Water pH', 'Soil pH', 'Water Salinity', 'Soil Salinity',
            'Total dissolved solids', 'Conduction', 'ORP', 
            'Specific resistance', 'Temp Â©', 'Conductivity',
            'P', 'PP', 'OC', 'H', 'C-A', 'C-B', 'C-C'
        ]
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§
        self.bio_indicators = [col for col in self.bio_indicators if col in self.data.columns]
        self.env_indicators = [col for col in self.env_indicators if col in self.data.columns]
        
        return len(self.bio_indicators), len(self.env_indicators)
    
    def calculate_correlation_analysis(self):
        """ìƒê´€ê´€ê³„ ë¶„ì„"""
        results = {
            'biological': {'correlations': [], 'indicators': [], 'p_values': []},
            'environmental': {'correlations': [], 'indicators': [], 'p_values': []}
        }
        
        # ìƒë¬¼í•™ì  ì§€í‘œ ìƒê´€ê´€ê³„
        for indicator in self.bio_indicators:
            clean_data = self.data[[indicator, self.pollution_target]].dropna()
            if len(clean_data) > 10:
                corr, p_val = pearsonr(clean_data[indicator], clean_data[self.pollution_target])
                results['biological']['correlations'].append(abs(corr))
                results['biological']['indicators'].append(indicator.split(' ')[0:3])
                results['biological']['p_values'].append(p_val)
        
        # í™˜ê²½ ì§€í‘œ ìƒê´€ê´€ê³„
        for indicator in self.env_indicators:
            clean_data = self.data[[indicator, self.pollution_target]].dropna()
            if len(clean_data) > 10:
                corr, p_val = pearsonr(clean_data[indicator], clean_data[self.pollution_target])
                results['environmental']['correlations'].append(abs(corr))
                results['environmental']['indicators'].append(indicator)
                results['environmental']['p_values'].append(p_val)
        
        self.results['correlation'] = results
        return results
    
    def calculate_predictive_power(self):
        """ì˜ˆì¸¡ë ¥ ë¹„êµ ë¶„ì„"""
        target = self.data[self.pollution_target].dropna()
        
        # ìƒë¬¼í•™ì  ì§€í‘œ ë°ì´í„°
        bio_data = self.data[self.bio_indicators].fillna(self.data[self.bio_indicators].median())
        bio_data = bio_data.loc[target.index]
        
        # í™˜ê²½ ì§€í‘œ ë°ì´í„°  
        env_data = self.data[self.env_indicators].fillna(self.data[self.env_indicators].median())
        env_data = env_data.loc[target.index]
        
        results = {}
        
        # Random Forest ë¶„ë¥˜ ì„±ëŠ¥
        rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
        
        if len(bio_data.columns) > 0:
            bio_scores = cross_val_score(rf_classifier, bio_data, target, cv=5, scoring='accuracy')
            results['bio_accuracy'] = bio_scores.mean()
            results['bio_accuracy_std'] = bio_scores.std()
        
        if len(env_data.columns) > 0:
            env_scores = cross_val_score(rf_classifier, env_data, target, cv=5, scoring='accuracy')
            results['env_accuracy'] = env_scores.mean()
            results['env_accuracy_std'] = env_scores.std()
        
        # Random Forest íšŒê·€ ì„±ëŠ¥ (RÂ²)
        rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)
        
        if len(bio_data.columns) > 0:
            bio_r2 = cross_val_score(rf_regressor, bio_data, target, cv=5, scoring='r2')
            results['bio_r2'] = bio_r2.mean()
            results['bio_r2_std'] = bio_r2.std()
        
        if len(env_data.columns) > 0:
            env_r2 = cross_val_score(rf_regressor, env_data, target, cv=5, scoring='r2')
            results['env_r2'] = env_r2.mean()
            results['env_r2_std'] = env_r2.std()
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
        combined_data = pd.concat([bio_data, env_data], axis=1)
        if len(combined_data.columns) > 0:
            rf_regressor.fit(combined_data, target)
            feature_importance = pd.DataFrame({
                'feature': combined_data.columns,
                'importance': rf_regressor.feature_importances_,
                'type': ['ìƒë¬¼í•™ì ' if col in self.bio_indicators else 'í™˜ê²½ì ' 
                        for col in combined_data.columns]
            }).sort_values('importance', ascending=False)
            
            results['feature_importance'] = feature_importance
        
        self.results['predictive_power'] = results
        return results
    
    def calculate_group_differences(self):
        """ì˜¤ì—¼ë„ë³„ ê·¸ë£¹ ì°¨ì´ ë¶„ì„"""
        results = {'biological': [], 'environmental': []}
        
        # ìƒë¬¼í•™ì  ì§€í‘œ ê·¸ë£¹ ì°¨ì´
        for indicator in self.bio_indicators:
            clean_data = self.data[[indicator, self.pollution_target]].dropna()
            if len(clean_data) > 20:
                groups = []
                for level in sorted(clean_data[self.pollution_target].unique()):
                    group_data = clean_data[clean_data[self.pollution_target] == level][indicator]
                    if len(group_data) >= 3:
                        groups.append(group_data)
                
                if len(groups) >= 2:
                    try:
                        statistic, p_value = stats.kruskal(*groups)
                        effect_size = self._calculate_effect_size(groups)
                        
                        results['biological'].append({
                            'indicator': indicator,
                            'p_value': p_value,
                            'effect_size': effect_size,
                            'significant': p_value < 0.05
                        })
                    except:
                        pass
        
        # í™˜ê²½ ì§€í‘œ ê·¸ë£¹ ì°¨ì´
        for indicator in self.env_indicators:
            clean_data = self.data[[indicator, self.pollution_target]].dropna()
            if len(clean_data) > 20:
                groups = []
                for level in sorted(clean_data[self.pollution_target].unique()):
                    group_data = clean_data[clean_data[self.pollution_target] == level][indicator]
                    if len(group_data) >= 3:
                        groups.append(group_data)
                
                if len(groups) >= 2:
                    try:
                        statistic, p_value = stats.kruskal(*groups)
                        effect_size = self._calculate_effect_size(groups)
                        
                        results['environmental'].append({
                            'indicator': indicator,
                            'p_value': p_value,
                            'effect_size': effect_size,
                            'significant': p_value < 0.05
                        })
                    except:
                        pass
        
        self.results['group_differences'] = results
        return results
    
    def _calculate_effect_size(self, groups):
        """íš¨ê³¼ í¬ê¸° ê³„ì‚° (eta-squared)"""
        all_values = np.concatenate(groups)
        overall_mean = np.mean(all_values)
        
        ss_between = sum(len(group) * (np.mean(group) - overall_mean)**2 for group in groups)
        ss_total = sum((value - overall_mean)**2 for value in all_values)
        
        return ss_between / ss_total if ss_total > 0 else 0
    
    def plot_correlation_comparison(self):
        """ìƒê´€ê´€ê³„ ë¹„êµ ì‹œê°í™”"""
        if 'correlation' not in self.results:
            self.calculate_correlation_analysis()
        
        corr_data = self.results['correlation']
        
        # ë°ì´í„° ì¤€ë¹„
        bio_corrs = corr_data['biological']['correlations']
        env_corrs = corr_data['environmental']['correlations']
        
        fig = go.Figure()
        
        # ë°•ìŠ¤í”Œë¡¯ìœ¼ë¡œ ë¶„í¬ ë¹„êµ
        fig.add_trace(go.Box(
            y=bio_corrs,
            name='ìƒë¬¼í•™ì  ì§€í‘œ',
            marker_color='lightgreen',
            boxpoints='all'
        ))
        
        fig.add_trace(go.Box(
            y=env_corrs,
            name='í™˜ê²½ ì§€í‘œ',
            marker_color='lightblue',
            boxpoints='all'
        ))
        
        fig.update_layout(
            title='ğŸ“Š ì˜¤ì—¼ë„ì™€ì˜ ìƒê´€ê´€ê³„ ê°•ë„ ë¹„êµ',
            yaxis_title='ì ˆëŒ€ ìƒê´€ê³„ìˆ˜',
            xaxis_title='ì§€í‘œ ìœ í˜•',
            height=500
        )
        
        return fig
    
    def plot_predictive_performance(self):
        """ì˜ˆì¸¡ ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”"""
        if 'predictive_power' not in self.results:
            self.calculate_predictive_power()
        
        results = self.results['predictive_power']
        
        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=('ë¶„ë¥˜ ì •í™•ë„', 'RÂ² ì ìˆ˜'),
            specs=[[{"type": "bar"}, {"type": "bar"}]]
        )
        
        # ë¶„ë¥˜ ì •í™•ë„
        categories = ['ìƒë¬¼í•™ì  ì§€í‘œ', 'í™˜ê²½ ì§€í‘œ']
        accuracies = [results.get('bio_accuracy', 0), results.get('env_accuracy', 0)]
        accuracy_errors = [results.get('bio_accuracy_std', 0), results.get('env_accuracy_std', 0)]
        
        fig.add_trace(
            go.Bar(
                x=categories,
                y=accuracies,
                error_y=dict(type='data', array=accuracy_errors),
                marker_color=['lightgreen', 'lightblue'],
                name='ì •í™•ë„'
            ),
            row=1, col=1
        )
        
        # RÂ² ì ìˆ˜
        r2_scores = [results.get('bio_r2', 0), results.get('env_r2', 0)]
        r2_errors = [results.get('bio_r2_std', 0), results.get('env_r2_std', 0)]
        
        fig.add_trace(
            go.Bar(
                x=categories,
                y=r2_scores,
                error_y=dict(type='data', array=r2_errors),
                marker_color=['lightgreen', 'lightblue'],
                name='RÂ² ì ìˆ˜'
            ),
            row=1, col=2
        )
        
        fig.update_layout(
            title='ğŸ¯ ì˜¤ì—¼ë„ ì˜ˆì¸¡ ì„±ëŠ¥ ë¹„êµ',
            showlegend=False,
            height=500
        )
        
        return fig
    
    def plot_feature_importance(self):
        """íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”"""
        if 'predictive_power' not in self.results or 'feature_importance' not in self.results['predictive_power']:
            self.calculate_predictive_power()
        
        importance_df = self.results['predictive_power']['feature_importance']
        top_features = importance_df.head(15)
        
        fig = px.bar(
            top_features,
            x='importance',
            y='feature',
            color='type',
            orientation='h',
            title='ğŸ” ê°œë³„ ì§€í‘œ ì¤‘ìš”ë„ Top 15',
            labels={'importance': 'ì¤‘ìš”ë„', 'feature': 'ì§€í‘œ', 'type': 'ìœ í˜•'},
            color_discrete_map={'ìƒë¬¼í•™ì ': 'lightgreen', 'í™˜ê²½ì ': 'lightblue'}
        )
        
        fig.update_layout(
            yaxis={'categoryorder': 'total ascending'},
            height=600
        )
        
        return fig
    
    def plot_pollution_distribution(self):
        """ì˜¤ì—¼ë„ë³„ ì§€í‘œ ë¶„í¬ ë¹„êµ"""
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('ì„ ì¶©ë¥˜ vs ì˜¤ì—¼ë„', 'pH vs ì˜¤ì—¼ë„', 'í„°ë¹Œë¼ë¦¬ì•„ vs ì˜¤ì—¼ë„', 'ì—¼ë¶„ vs ì˜¤ì—¼ë„')
        )
        
        pollution_levels = self.data[self.pollution_target].unique()
        colors = ['green', 'orange', 'red']
        
        # ì„ ì¶©ë¥˜ vs ì˜¤ì—¼ë„
        if 'Mean Number of Nematode species 1 per gram soil' in self.data.columns:
            for i, level in enumerate(sorted(pollution_levels)):
                level_data = self.data[self.data[self.pollution_target] == level]
                fig.add_trace(
                    go.Box(
                        y=level_data['Mean Number of Nematode species 1 per gram soil'],
                        name=f'ìˆ˜ì¤€ {level}',
                        marker_color=colors[i % len(colors)],
                        showlegend=False
                    ),
                    row=1, col=1
                )
        
        # pH vs ì˜¤ì—¼ë„
        if 'Water pH' in self.data.columns:
            for i, level in enumerate(sorted(pollution_levels)):
                level_data = self.data[self.data[self.pollution_target] == level]
                fig.add_trace(
                    go.Box(
                        y=level_data['Water pH'],
                        name=f'ìˆ˜ì¤€ {level}',
                        marker_color=colors[i % len(colors)],
                        showlegend=False
                    ),
                    row=1, col=2
                )
        
        # í„°ë¹Œë¼ë¦¬ì•„ vs ì˜¤ì—¼ë„
        if 'Mean Number of Turbillaria per gram soil' in self.data.columns:
            for i, level in enumerate(sorted(pollution_levels)):
                level_data = self.data[self.data[self.pollution_target] == level]
                fig.add_trace(
                    go.Box(
                        y=level_data['Mean Number of Turbillaria per gram soil'],
                        name=f'ìˆ˜ì¤€ {level}',
                        marker_color=colors[i % len(colors)],
                        showlegend=False
                    ),
                    row=2, col=1
                )
        
        # ì—¼ë¶„ vs ì˜¤ì—¼ë„
        if 'Water Salinity' in self.data.columns:
            for i, level in enumerate(sorted(pollution_levels)):
                level_data = self.data[self.data[self.pollution_target] == level]
                fig.add_trace(
                    go.Box(
                        y=level_data['Water Salinity'],
                        name=f'ìˆ˜ì¤€ {level}',
                        marker_color=colors[i % len(colors)],
                        showlegend=False
                    ),
                    row=2, col=2
                )
        
        fig.update_layout(
            title='ğŸ“ˆ ì˜¤ì—¼ë„ë³„ ì£¼ìš” ì§€í‘œ ë¶„í¬',
            height=600
        )
        
        return fig
    
    def plot_indicator_correlation_heatmap(self):
        """ì§€í‘œê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ"""
        # ì£¼ìš” ì§€í‘œë“¤ ì„ íƒ
        key_indicators = []
        if self.bio_indicators:
            key_indicators.extend(self.bio_indicators[:3])
        if self.env_indicators:
            key_indicators.extend(self.env_indicators[:5])
        key_indicators.append(self.pollution_target)
        
        # ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
        corr_matrix = self.data[key_indicators].corr()
        
        fig = px.imshow(
            corr_matrix,
            title='ğŸ”— ì£¼ìš” ì§€í‘œê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ',
            color_continuous_scale='RdBu',
            zmin=-1, zmax=1
        )
        
        return fig
    
    def generate_summary_report(self):
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not all(key in self.results for key in ['correlation', 'predictive_power']):
            self.calculate_correlation_analysis()
            self.calculate_predictive_power()
            self.calculate_group_differences()
        
        report = {
            'correlation_summary': {},
            'prediction_summary': {},
            'recommendation': ""
        }
        
        # ìƒê´€ê´€ê³„ ìš”ì•½
        corr_data = self.results['correlation']
        bio_corr_avg = np.mean(corr_data['biological']['correlations']) if corr_data['biological']['correlations'] else 0
        env_corr_avg = np.mean(corr_data['environmental']['correlations']) if corr_data['environmental']['correlations'] else 0
        
        report['correlation_summary'] = {
            'bio_avg_correlation': bio_corr_avg,
            'env_avg_correlation': env_corr_avg,
            'better_correlator': 'ìƒë¬¼í•™ì  ì§€í‘œ' if bio_corr_avg > env_corr_avg else 'í™˜ê²½ ì§€í‘œ'
        }
        
        # ì˜ˆì¸¡ ì„±ëŠ¥ ìš”ì•½
        pred_data = self.results['predictive_power']
        bio_accuracy = pred_data.get('bio_accuracy', 0)
        env_accuracy = pred_data.get('env_accuracy', 0)
        bio_r2 = pred_data.get('bio_r2', 0)
        env_r2 = pred_data.get('env_r2', 0)
        
        report['prediction_summary'] = {
            'bio_accuracy': bio_accuracy,
            'env_accuracy': env_accuracy,
            'bio_r2': bio_r2,
            'env_r2': env_r2,
            'better_predictor': 'ìƒë¬¼í•™ì  ì§€í‘œ' if (bio_accuracy + bio_r2) > (env_accuracy + env_r2) else 'í™˜ê²½ ì§€í‘œ'
        }
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if bio_corr_avg > env_corr_avg and (bio_accuracy + bio_r2) > (env_accuracy + env_r2):
            report['recommendation'] = "ìƒë¬¼í•™ì  ì§€í‘œê°€ ì˜¤ì—¼ë„ë¥¼ ë” ì˜ ì„¤ëª…í•©ë‹ˆë‹¤. ìƒë¬¼ë‹¤ì–‘ì„± ëª¨ë‹ˆí„°ë§ì— ì§‘ì¤‘í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
        elif env_corr_avg > bio_corr_avg and (env_accuracy + env_r2) > (bio_accuracy + bio_r2):
            report['recommendation'] = "í™˜ê²½ ì§€í‘œê°€ ì˜¤ì—¼ë„ë¥¼ ë” ì˜ ì„¤ëª…í•©ë‹ˆë‹¤. í™”í•™ì Â·ë¬¼ë¦¬ì  í™˜ê²½ ëª¨ë‹ˆí„°ë§ì— ì§‘ì¤‘í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
        else:
            report['recommendation'] = "ìƒë¬¼í•™ì  ì§€í‘œì™€ í™˜ê²½ ì§€í‘œ ëª¨ë‘ ì¤‘ìš”í•©ë‹ˆë‹¤. í†µí•©ì ì¸ ëª¨ë‹ˆí„°ë§ ì ‘ê·¼ë²•ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
        
        return report

# Streamlit ì•± ë©”ì¸ í•¨ìˆ˜
def main():
    st.set_page_config(
        page_title="ì˜¤ì—¼ë„ ì§€í‘œ ë¹„êµ ë¶„ì„",
        page_icon="ğŸŒŠ",
        layout="wide"
    )
    
    st.title("ğŸŒŠ ìƒë¬¼ ë‹¤ì–‘ì„± vs í™˜ê²½ ì§€í‘œ: ì˜¤ì—¼ë„ ì„¤ëª…ë ¥ ë¹„êµ")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°”
    st.sidebar.title("ğŸ“‹ ë¶„ì„ ì„¤ì •")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.sidebar.file_uploader(
        "CSV íŒŒì¼ ì—…ë¡œë“œ",
        type=['csv'],
        help="Shore_Pollution.csv íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    if uploaded_file is not None:
        # ë°ì´í„° ë¡œë“œ
        try:
            data = pd.read_csv(uploaded_file)
            st.sidebar.success(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(data)}ê°œ ìƒ˜í”Œ")
            
            # ë¶„ì„ê¸° ì´ˆê¸°í™”
            analyzer = PollutionIndicatorAnalyzer()
            bio_count, env_count = analyzer.load_data(data)
            
            st.sidebar.info(f"ğŸ¦  ìƒë¬¼ ì§€í‘œ: {bio_count}ê°œ")
            st.sidebar.info(f"ğŸŒ¡ï¸ í™˜ê²½ ì§€í‘œ: {env_count}ê°œ")
            
            # ë¶„ì„ ì˜µì…˜
            analysis_options = st.sidebar.multiselect(
                "ë¶„ì„ ìœ í˜• ì„ íƒ",
                ["ìƒê´€ê´€ê³„ ë¶„ì„", "ì˜ˆì¸¡ ì„±ëŠ¥ ë¹„êµ", "íŠ¹ì„± ì¤‘ìš”ë„", "ë¶„í¬ ë¹„êµ", "ì¢…í•© ë¦¬í¬íŠ¸"],
                default=["ìƒê´€ê´€ê³„ ë¶„ì„", "ì˜ˆì¸¡ ì„±ëŠ¥ ë¹„êµ"]
            )
            
            # ë©”ì¸ ì»¨í…ì¸ 
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
                
                if "ìƒê´€ê´€ê³„ ë¶„ì„" in analysis_options:
                    st.subheader("1. ìƒê´€ê´€ê³„ ê°•ë„ ë¹„êµ")
                    with st.spinner("ìƒê´€ê´€ê³„ ë¶„ì„ ì¤‘..."):
                        fig_corr = analyzer.plot_correlation_comparison()
                        st.plotly_chart(fig_corr, use_container_width=True)
                
                if "ì˜ˆì¸¡ ì„±ëŠ¥ ë¹„êµ" in analysis_options:
                    st.subheader("2. ì˜¤ì—¼ë„ ì˜ˆì¸¡ ì„±ëŠ¥")
                    with st.spinner("ì˜ˆì¸¡ ì„±ëŠ¥ ê³„ì‚° ì¤‘..."):
                        fig_pred = analyzer.plot_predictive_performance()
                        st.plotly_chart(fig_pred, use_container_width=True)
                
                if "íŠ¹ì„± ì¤‘ìš”ë„" in analysis_options:
                    st.subheader("3. ê°œë³„ ì§€í‘œ ì¤‘ìš”ë„")
                    with st.spinner("íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì¤‘..."):
                        fig_importance = analyzer.plot_feature_importance()
                        st.plotly_chart(fig_importance, use_container_width=True)
                
                if "ë¶„í¬ ë¹„êµ" in analysis_options:
                    st.subheader("4. ì˜¤ì—¼ë„ë³„ ì§€í‘œ ë¶„í¬")
                    with st.spinner("ë¶„í¬ ë¶„ì„ ì¤‘..."):
                        fig_dist = analyzer.plot_pollution_distribution()
                        st.plotly_chart(fig_dist, use_container_width=True)
                        
                        fig_heatmap = analyzer.plot_indicator_correlation_heatmap()
                        st.plotly_chart(fig_heatmap, use_container_width=True)
            
            with col2:
                st.header("ğŸ“‹ ìš”ì•½ ì •ë³´")
                
                # ë°ì´í„° ê°œìš”
                st.subheader("ë°ì´í„° ê°œìš”")
                st.metric("ì´ ìƒ˜í”Œ ìˆ˜", len(data))
                st.metric("ì˜¤ì—¼ ìˆ˜ì¤€", len(data['Pollution Level'].unique()))
                st.metric("ì¡°ì‚¬ í•´ì•ˆ", len(data['Shore'].unique()))
                
                # ì˜¤ì—¼ë„ ë¶„í¬
                st.subheader("ì˜¤ì—¼ë„ ë¶„í¬")
                pollution_dist = data['Pollution Level'].value_counts().sort_index()
                for level, count in pollution_dist.items():
                    st.metric(f"ìˆ˜ì¤€ {level}", f"{count}ê°œ", f"{count/len(data)*100:.1f}%")
                
                if "ì¢…í•© ë¦¬í¬íŠ¸" in analysis_options:
                    st.subheader("ğŸ¯ ì¢…í•© ë¶„ì„ ê²°ê³¼")
                    with st.spinner("ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
                        report = analyzer.generate_summary_report()
                        
                        st.write("**ìƒê´€ê´€ê³„ ë¶„ì„:**")
                        st.write(f"â€¢ ìƒë¬¼í•™ì  ì§€í‘œ í‰ê· : {report['correlation_summary']['bio_avg_correlation']:.3f}")
                        st.write(f"â€¢ í™˜ê²½ ì§€í‘œ í‰ê· : {report['correlation_summary']['env_avg_correlation']:.3f}")
                        st.write(f"â€¢ ë” ê°•í•œ ìƒê´€ê´€ê³„: {report['correlation_summary']['better_correlator']}")
                        
                        st.write("**ì˜ˆì¸¡ ì„±ëŠ¥:**")
                        st.write(f"â€¢ ìƒë¬¼í•™ì  ì •í™•ë„: {report['prediction_summary']['bio_accuracy']:.3f}")
                        st.write(f"â€¢ í™˜ê²½ ì§€í‘œ ì •í™•ë„: {report['prediction_summary']['env_accuracy']:.3f}")
                        st.write(f"â€¢ ë” ë‚˜ì€ ì˜ˆì¸¡ë ¥: {report['prediction_summary']['better_predictor']}")
                        
                        st.success(f"**ê¶Œì¥ì‚¬í•­:** {report['recommendation']}")
            
            # ìƒì„¸ í†µê³„ ì •ë³´
            if st.checkbox("ìƒì„¸ í†µê³„ ì •ë³´ ë³´ê¸°"):
                st.subheader("ğŸ“ˆ ìƒì„¸ í†µê³„")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**ìƒë¬¼í•™ì  ì§€í‘œ:**")
                    for indicator in analyzer.bio_indicators:
                        clean_data = data[[indicator, 'Pollution Level']].dropna()
                        if len(clean_data) > 0:
                            corr, p_val = pearsonr(clean_data[indicator], clean_data['Pollution Level'])
                            st.write(f"â€¢ {indicator[:20]}...: r={corr:.3f}, p={p_val:.3f}")
                
                with col2:
                    st.write("**í™˜ê²½ ì§€í‘œ:**")
                    for indicator in analyzer.env_indicators[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                        clean_data = data[[indicator, 'Pollution Level']].dropna()
                        if len(clean_data) > 0:
                            corr, p_val = pearsonr(clean_data[indicator], clean_data['Pollution Level'])
                            st.write(f"â€¢ {indicator}: r={corr:.3f}, p={p_val:.3f}")
                        
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    else:
        st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
        
        # ìƒ˜í”Œ ë°ì´í„° êµ¬ì¡° ì„¤ëª…
        st.subheader("ğŸ“‹ í•„ìš”í•œ ë°ì´í„° êµ¬ì¡°")
        st.write("""
        **í•„ìˆ˜ ì»¬ëŸ¼:**
        - `Pollution Level`: ì˜¤ì—¼ ìˆ˜ì¤€ (0, 1, 2)
        - `Shore`: í•´ì•ˆ ì§€ì 
        - `Month`, `Season`: ì‹œê°„ ì •ë³´
        
        **ìƒë¬¼í•™ì  ì§€í‘œ:**
        - `Mean Number of Nematode species 1 per gram soil`
        - `Mean Number of Turbillaria per gram soil`
        - `Mean Number of foraminefera per gram soil`
        
        **í™˜ê²½ ì§€í‘œ:**
        - `Water pH`, `Soil pH`
        - `Water Salinity`, `Soil Salinity`
        - `Total dissolved solids`
        - `Conduction`, `ORP`, `Temp Â©`
        """)

if __name__ == "__main__":
    main()
