import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import warnings
import os
warnings.filterwarnings('ignore')

class ShorePollutionPredictor:
    """
    í•´ì•ˆ ì˜¤ì—¼ ì˜ˆì¸¡ ëª¨ë¸ í´ë˜ìŠ¤
   
    ì´ ëª¨ë¸ì€ í•´ì•ˆì˜ ìƒë¬¼í•™ì , í™”í•™ì , ë¬¼ë¦¬ì  ì§€í‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    ì˜¤ì—¼ ìˆ˜ì¤€(0: ë‚®ìŒ, 1: ë³´í†µ, 2: ë†’ìŒ)ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """
   
    def __init__(self):
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.scaler = StandardScaler()
        self.feature_columns = None
        self.feature_importance = None
        self.is_trained = False
        self.data = None
       
    def load_data(self, filepath):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        try:
            if not os.path.exists(filepath):
                raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
            
            self.data = pd.read_csv(filepath)
            
            # ë°ì´í„° ê¸°ë³¸ ê²€ì¦
            if self.data.empty:
                raise ValueError("ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                
            # í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
            required_columns = ['Pollution Level']
            missing_columns = [col for col in required_columns if col not in self.data.columns]
            if missing_columns:
                raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_columns}")
            
            print(f"ğŸ“Š ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.data)}ê°œ ìƒ˜í”Œ")
            print(f"ğŸ“Š ì»¬ëŸ¼ ìˆ˜: {len(self.data.columns)}")
            print(f"ğŸ“Š ê²°ì¸¡ê°’ í˜„í™©:")
            print(self.data.isnull().sum().sort_values(ascending=False).head(10))
            
            return self.data
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
   
    def preprocess_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        if self.data is None:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸ ë° ì£¼ìš” íŠ¹ì„± ì„ íƒ
        available_columns = self.data.columns.tolist()
        
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ íŠ¹ì„± ì„ íƒ
        potential_features = [
            'Month', 'Season', 'Shore',
            'Mean Number of Nematode species 1 per gram soil',
            'Mean Number of Turbillaria per gram soil',
            'Water pH', 'Soil pH', 'Water Salinity', 'Soil Salinity',
            'Total dissolved solids', 'Conduction', 'ORP'
        ]
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        self.feature_columns = [col for col in potential_features if col in available_columns]
        
        if not self.feature_columns:
            raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„± ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"ğŸ“‹ ì‚¬ìš©í•  íŠ¹ì„± ì»¬ëŸ¼: {len(self.feature_columns)}ê°œ")
        for col in self.feature_columns:
            print(f"  - {col}")
       
        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        X = self.data[self.feature_columns].copy()
        y = self.data['Pollution Level']
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ê²€ì¦
        if y.isnull().sum() > 0:
            print(f"âš ï¸ íƒ€ê²Ÿ ë³€ìˆ˜ì— ê²°ì¸¡ê°’ì´ {y.isnull().sum()}ê°œ ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ í–‰ì„ ì œê±°í•©ë‹ˆë‹¤.")
            valid_idx = ~y.isnull()
            X = X[valid_idx]
            y = y[valid_idx]
       
        # ê²°ì¸¡ê°’ ì²˜ë¦¬ (ìˆ˜ì¹˜í˜•ì€ ì¤‘ì•™ê°’, ë²”ì£¼í˜•ì€ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´)
        for col in X.columns:
            if X[col].dtype in ['int64', 'float64']:
                X[col] = X[col].fillna(X[col].median())
            else:
                X[col] = X[col].fillna(X[col].mode()[0] if not X[col].mode().empty else 0)
        
        # ë¬´í•œê°’ ì²˜ë¦¬
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(X.median())
        
        print(f"ğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œ: {len(X)}ê°œ ìƒ˜í”Œ, {len(X.columns)}ê°œ íŠ¹ì„±")
        
        return X, y
   
    def train_model(self, test_size=0.2):
        """ëª¨ë¸ í›ˆë ¨"""
        try:
            X, y = self.preprocess_data()
            
            # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ í™•ì¸
            if len(X) < 10:
                raise ValueError("í›ˆë ¨ì„ ìœ„í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            
            # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
            class_counts = y.value_counts()
            print(f"ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:")
            for class_val, count in class_counts.items():
                print(f"  í´ë˜ìŠ¤ {class_val}: {count}ê°œ")
            
            # ê° í´ë˜ìŠ¤ì— ìµœì†Œ 2ê°œ ì´ìƒì˜ ìƒ˜í”Œì´ ìˆëŠ”ì§€ í™•ì¸
            if any(count < 2 for count in class_counts.values()):
                print("âš ï¸ ì¼ë¶€ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œì´ ë¶€ì¡±í•©ë‹ˆë‹¤. stratify ì˜µì…˜ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.")
                stratify_param = None
            else:
                stratify_param = y
       
            # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=stratify_param
            )
       
            # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
       
            # ëª¨ë¸ í›ˆë ¨
            self.model.fit(X_train_scaled, y_train)
       
            # ì˜ˆì¸¡ ë° í‰ê°€
            y_pred = self.model.predict(X_test_scaled)
       
            # íŠ¹ì„± ì¤‘ìš”ë„ ì €ì¥
            self.feature_importance = pd.DataFrame({
                'feature': self.feature_columns,
                'importance': self.model.feature_importances_
            }).sort_values('importance', ascending=False)
       
            self.is_trained = True
       
            # ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥
            print("ğŸ¯ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€:")
            print(f"ì •í™•ë„: {accuracy_score(y_test, y_pred):.3f}")
            print(f"í›ˆë ¨ ì„¸íŠ¸ í¬ê¸°: {len(X_train)}")
            print(f"í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í¬ê¸°: {len(X_test)}")
            print("\në¶„ë¥˜ ë³´ê³ ì„œ:")
            print(classification_report(y_test, y_pred, zero_division=0))
       
            return X_train, X_test, y_train, y_test, y_pred
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None, None, None, None, None
   
    def predict(self, new_data):
        """ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡"""
        if not self.is_trained:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train_model()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        if self.data is None:
            raise ValueError("ì›ë³¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ì„ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.")
       
        try:
            # ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
            if isinstance(new_data, dict):
                new_data = pd.DataFrame([new_data])
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            missing_cols = [col for col in self.feature_columns if col not in new_data.columns]
            if missing_cols:
                raise ValueError(f"ì˜ˆì¸¡ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_cols}")
            
            X_new = new_data[self.feature_columns].copy()
            
            # ê²°ì¸¡ê°’ ì²˜ë¦¬
            for col in X_new.columns:
                if X_new[col].dtype in ['int64', 'float64']:
                    X_new[col] = X_new[col].fillna(self.data[col].median())
                else:
                    mode_val = self.data[col].mode()
                    X_new[col] = X_new[col].fillna(mode_val[0] if not mode_val.empty else 0)
            
            # ë¬´í•œê°’ ì²˜ë¦¬
            X_new = X_new.replace([np.inf, -np.inf], np.nan)
            for col in X_new.columns:
                if X_new[col].dtype in ['int64', 'float64']:
                    X_new[col] = X_new[col].fillna(self.data[col].median())
            
            X_new_scaled = self.scaler.transform(X_new)
       
            # ì˜ˆì¸¡
            prediction = self.model.predict(X_new_scaled)
            probability = self.model.predict_proba(X_new_scaled)
       
            return prediction, probability
            
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None, None
   
    def plot_data_overview(self):
        """ë°ì´í„° ê°œìš” ì‹œê°í™”"""
        if self.data is None:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        try:
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('ì˜¤ì—¼ ìˆ˜ì¤€ë³„ ë¶„í¬', 'í•´ì•ˆë³„ ìƒ˜í”Œ ìˆ˜', 'ê³„ì ˆë³„ ë¶„í¬', 'ì›”ë³„ íŠ¸ë Œë“œ'),
                specs=[[{"type": "bar"}, {"type": "bar"}],
                       [{"type": "bar"}, {"type": "scatter"}]]
            )
           
            # ì˜¤ì—¼ ìˆ˜ì¤€ë³„ ë¶„í¬
            pollution_counts = self.data['Pollution Level'].value_counts().sort_index()
            fig.add_trace(
                go.Bar(x=pollution_counts.index, y=pollution_counts.values,
                       name='ì˜¤ì—¼ ìˆ˜ì¤€', marker_color='lightcoral'),
                row=1, col=1
            )
           
            # í•´ì•ˆë³„ ìƒ˜í”Œ ìˆ˜ (ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ)
            if 'Shore' in self.data.columns:
                shore_counts = self.data['Shore'].value_counts().sort_index()
                fig.add_trace(
                    go.Bar(x=shore_counts.index, y=shore_counts.values,
                           name='í•´ì•ˆë³„', marker_color='lightblue'),
                    row=1, col=2
                )
           
            # ê³„ì ˆë³„ ë¶„í¬ (ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ)
            if 'Season' in self.data.columns:
                season_counts = self.data['Season'].value_counts().sort_index()
                fig.add_trace(
                    go.Bar(x=season_counts.index, y=season_counts.values,
                           name='ê³„ì ˆë³„', marker_color='lightgreen'),
                    row=2, col=1
                )
           
            # ì›”ë³„ íŠ¸ë Œë“œ (ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ)
            if 'Month' in self.data.columns:
                monthly_pollution = self.data.groupby('Month')['Pollution Level'].mean()
                fig.add_trace(
                    go.Scatter(x=monthly_pollution.index, y=monthly_pollution.values,
                              mode='lines+markers', name='ì›”ë³„ í‰ê·  ì˜¤ì—¼ë„',
                              line=dict(color='orange', width=3)),
                    row=2, col=2
                )
           
            fig.update_layout(
                title_text="ğŸŒŠ í•´ì•ˆ ì˜¤ì—¼ ë°ì´í„° ê°œìš”",
                showlegend=False,
                height=600
            )
           
            return fig
            
        except Exception as e:
            print(f"âŒ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
   
    def plot_feature_importance(self):
        """íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”"""
        if not self.is_trained:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        if self.feature_importance is None:
            raise ValueError("íŠ¹ì„± ì¤‘ìš”ë„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        try:
            fig = px.bar(
                self.feature_importance.head(min(10, len(self.feature_importance))),
                x='importance',
                y='feature',
                orientation='h',
                title='ğŸ¯ íŠ¹ì„± ì¤‘ìš”ë„ (Top 10)',
                labels={'importance': 'ì¤‘ìš”ë„', 'feature': 'íŠ¹ì„±'}
            )
           
            fig.update_layout(
                yaxis={'categoryorder': 'total ascending'},
                height=max(400, len(self.feature_importance.head(10)) * 50)
            )
           
            return fig
            
        except Exception as e:
            print(f"âŒ íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
   
    def plot_pollution_heatmap(self):
        """í•´ì•ˆë³„ ì˜¤ì—¼ ìˆ˜ì¤€ íˆíŠ¸ë§µ"""
        if self.data is None:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['Shore', 'Season', 'Pollution Level']
        missing_cols = [col for col in required_cols if col not in self.data.columns]
        
        if missing_cols:
            print(f"âš ï¸ íˆíŠ¸ë§µ ìƒì„±ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_cols}")
            return None
        
        try:
            # í•´ì•ˆë³„, ê³„ì ˆë³„ í‰ê·  ì˜¤ì—¼ë„
            heatmap_data = self.data.pivot_table(
                values='Pollution Level',
                index='Shore',
                columns='Season',
                aggfunc='mean'
            )
           
            if heatmap_data.empty:
                print("âš ï¸ íˆíŠ¸ë§µ ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                return None
            
            fig = px.imshow(
                heatmap_data,
                title='ğŸ—ºï¸ í•´ì•ˆë³„-ê³„ì ˆë³„ í‰ê·  ì˜¤ì—¼ë„',
                labels=dict(x="ê³„ì ˆ", y="í•´ì•ˆ", color="ì˜¤ì—¼ ìˆ˜ì¤€"),
                color_continuous_scale='Reds'
            )
           
            return fig
            
        except Exception as e:
            print(f"âŒ íˆíŠ¸ë§µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
   
    def plot_correlation_matrix(self):
        """ì£¼ìš” ë³€ìˆ˜ë“¤ ê°„ ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤"""
        if self.data is None:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ë§Œ ì„ íƒ
            numeric_cols = [
                'Pollution Level', 'Water pH', 'Soil pH',
                'Water Salinity', 'Soil Salinity',
                'Mean Number of Nematode species 1 per gram soil',
                'Mean Number of Turbillaria per gram soil'
            ]
            
            # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
            available_numeric_cols = [col for col in numeric_cols if col in self.data.columns]
            
            if len(available_numeric_cols) < 2:
                print("âš ï¸ ìƒê´€ê´€ê³„ ë¶„ì„ì„ ìœ„í•œ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                return None
            
            correlation_matrix = self.data[available_numeric_cols].corr()
           
            fig = px.imshow(
                correlation_matrix,
                title='ğŸ”— ì£¼ìš” ë³€ìˆ˜ë“¤ ê°„ ìƒê´€ê´€ê³„',
                color_continuous_scale='RdBu',
                zmin=-1, zmax=1
            )
           
            return fig
            
        except Exception as e:
            print(f"âŒ ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
   
    def generate_report(self):
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        if self.data is None:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        if not self.is_trained:
            print("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            result = self.train_model()
            if result[0] is None:  # í›ˆë ¨ ì‹¤íŒ¨
                print("âŒ ëª¨ë¸ í›ˆë ¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¦¬í¬íŠ¸ ìƒì„±ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return None
       
        try:
            print("=" * 60)
            print("ğŸŒŠ í•´ì•ˆ ì˜¤ì—¼ ì˜ˆì¸¡ ëª¨ë¸ ë¦¬í¬íŠ¸")
            print("=" * 60)
           
            print(f"\nğŸ“Š ë°ì´í„° ê°œìš”:")
            print(f"â€¢ ì´ ìƒ˜í”Œ ìˆ˜: {len(self.data)}")
            
            if 'Shore' in self.data.columns:
                print(f"â€¢ í•´ì•ˆ ìˆ˜: {self.data['Shore'].nunique()}")
            
            if 'Month' in self.data.columns:
                print(f"â€¢ ì¡°ì‚¬ ê¸°ê°„: {self.data['Month'].min()}ì›” ~ {self.data['Month'].max()}ì›”")
           
            print(f"\nâš ï¸ ì˜¤ì—¼ ìˆ˜ì¤€ë³„ ë¶„í¬:")
            for level in sorted(self.data['Pollution Level'].unique()):
                count = (self.data['Pollution Level'] == level).sum()
                print(f"â€¢ ìˆ˜ì¤€ {level}: {count}ê°œ ({count/len(self.data)*100:.1f}%)")
           
            if self.feature_importance is not None:
                print(f"\nğŸ¯ ìƒìœ„ 5ê°œ ì¤‘ìš” íŠ¹ì„±:")
                for i, row in self.feature_importance.head(5).iterrows():
                    print(f"â€¢ {row['feature']}: {row['importance']:.3f}")
           
            return self.feature_importance
            
        except Exception as e:
            print(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

# ì‚¬ìš© ì˜ˆì œ
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ëª¨ë¸ ì´ˆê¸°í™”
    predictor = ShorePollutionPredictor()
   
    # ë°ì´í„° ë¡œë“œ (íŒŒì¼ ê²½ë¡œë¥¼ ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”)
    # data = predictor.load_data('Shore_Pollution.csv')
    
    # ë°ì´í„° ë¡œë“œê°€ ì„±ê³µí•œ ê²½ìš°ì—ë§Œ ê³„ì† ì§„í–‰
    # if data is not None:
    #     # ëª¨ë¸ í›ˆë ¨
    #     predictor.train_model()
    #     
    #     # ì‹œê°í™”
    #     fig1 = predictor.plot_data_overview()
    #     if fig1 is not None:
    #         fig1.show()
    #     
    #     fig2 = predictor.plot_feature_importance()
    #     if fig2 is not None:
    #         fig2.show()
    #     
    #     fig3 = predictor.plot_pollution_heatmap()
    #     if fig3 is not None:
    #         fig3.show()
    #     
    #     # ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡ ì˜ˆì œ
    #     new_sample = {
    #         'Month': 8,
    #         'Season': 4,
    #         'Shore': 1,
    #         'Mean Number of Nematode species 1 per gram soil': 5.7,
    #         'Mean Number of Turbillaria per gram soil': 0.15,
    #         'Water pH': 8.0,
    #         'Soil pH': 8.2,
    #         'Water Salinity': 38.5,
    #         'Soil Salinity': 11.0,
    #         'Total dissolved solids': 57500,
    #         'Conduction': 57400,
    #         'ORP': -79.9
    #     }
    #     
    #     prediction, probability = predictor.predict(new_sample)
    #     if prediction is not None:
    #         print(f"ì˜ˆì¸¡ ê²°ê³¼: ì˜¤ì—¼ ìˆ˜ì¤€ {prediction[0]}")
    #         print(f"ì˜ˆì¸¡ í™•ë¥ : {probability[0]}")
    #     
    #     # ë¦¬í¬íŠ¸ ìƒì„±
    #     predictor.generate_report()
    
    print("ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ. ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
